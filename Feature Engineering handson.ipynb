{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb842986-a02b-4537-8752-4d65816036e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A critical part of the successful Machine Learning project is coming up\n",
    "#with a good set of features to train on. This process is called feature engineering,\n",
    "#and it involves three steps: feature transformation (transforming the original features), \n",
    "#feature selection (selecting the most useful features to train on), and feature extraction\n",
    "#(combining existing features to produce more useful ones). In this notebook we will explore\n",
    "#different tools in Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4abff0e-ae03-4073-b2d5-1da0114d8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9d7507-84e5-4743-b640-cdcaadf3f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff13c647-f28a-48c3-a356-8410c5498297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n",
       "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897  \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662  \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882  \n",
       "3    18:05         23:30   5h 25m      1 stop         No info   6218  \n",
       "4    16:50         21:35   4h 45m      1 stop         No info  13302  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Data/airlines_data.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72135e03-9b42-4343-b72f-04de01d7b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab2ce514-8cd3-4371-bf75-429daf2b9150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9087.064121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4611.359167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1759.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12373.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79512.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price\n",
       "count  10683.000000\n",
       "mean    9087.064121\n",
       "std     4611.359167\n",
       "min     1759.000000\n",
       "25%     5277.000000\n",
       "50%     8372.000000\n",
       "75%    12373.000000\n",
       "max    79512.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "444e63df-f00e-407a-bfa2-b37612b56367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              1\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        1\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2af9788a-aa87-4745-b14c-3353513772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have found some null points, we need to either remove them from our dataset or fill \n",
    "#them with something else\n",
    "\n",
    "#we will use fillna() and method='ffill', which fills the last observed non-null \n",
    "#value forward until another non-null value is encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8017461-0394-49f1-b2f6-f1fdd7f58335",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f31eaa3-ebde-4023-87d1-fa038c8a16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Transformation\n",
    "\n",
    "#Feature Transformation means transforming our features to the functions of the original \n",
    "#features. For example, feature encoding, scaling, and discretization (the process\n",
    "#of transforming continuous variables into discrete form, by creating bins or intervals)\n",
    "#are the most common forms of data transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d70be1-133d-4e00-934b-e25adb89e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7112e96-af24-4237-b418-3881f8083152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical variables represent qualitative data with no apparent inherent\n",
    "#mathematical meaning. Therefore, for any machine learning analysis, all the\n",
    "#categorical data must be transformed into the numerical data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02d3d023-ff6c-4339-ba2f-5eb6d5bf1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we'll start with 'Airlines' column, as it contains categorical values. \n",
    "#We will use unique() method to obtain all the categories in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aad45a9c-299a-438a-b77c-6b11282061bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IndiGo',\n",
       " 'Air India',\n",
       " 'Jet Airways',\n",
       " 'SpiceJet',\n",
       " 'Multiple carriers',\n",
       " 'GoAir',\n",
       " 'Vistara',\n",
       " 'Air Asia',\n",
       " 'Vistara Premium economy',\n",
       " 'Jet Airways Business',\n",
       " 'Multiple carriers Premium economy',\n",
       " 'Trujet']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Airline'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8644a647-5085-4c12-b6d4-fb71359be232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above list, we notice that some of the airline names are being repeated.\n",
    "#For example, 'Jet Airways' and 'Jet Airways Business'. This means that some of the airlines are subdivided into separate parts. We will combine these 'two-parts' airlines to make our categorical features more consistent with the rest of the variables.\n",
    "\n",
    "#Here, we will use the numpy where() function to locate and combine the two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b154303-ba3e-4df2-8ef1-6df6d1aa89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Airline'] = np.where(data['Airline']=='Vistara Premium economy', 'Vistara', data['Airline'])\n",
    "data['Airline'] = np.where(data['Airline']=='Jet Airways Business', 'Jet Airways', data['Airline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c00afa70-4789-4a2d-abe7-b29c11b100b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "\n",
    "#Now, to be recognized by a machine learning algorithms, our categorical variables\n",
    "#should be converted into numerical ones. One way to do this is through one hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abe6f53c-d018-4842-88ae-4c86a94f3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use, get_dummies() method to do this transformation. In the next cell, we will \n",
    "#transform 'Airline', 'Source', and 'Destination' into their respective numeric variables. \n",
    "#We will put all the transformed data into a 'data1' data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd165d89-df1f-4214-a595-b13125c4dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Airline_Air Asia</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>...</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Banglore</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date_of_Journey                  Route Dep_Time  Arrival_Time Duration  \\\n",
       "0      24/03/2019              BLR → DEL    22:20  01:10 22 Mar   2h 50m   \n",
       "1       1/05/2019  CCU → IXR → BBI → BLR    05:50         13:15   7h 25m   \n",
       "2       9/06/2019  DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h   \n",
       "3      12/05/2019        CCU → NAG → BLR    18:05         23:30   5h 25m   \n",
       "4      01/03/2019        BLR → NAG → DEL    16:50         21:35   4h 45m   \n",
       "\n",
       "  Total_Stops Additional_Info  Price  Airline_Air Asia  Airline_Air India  \\\n",
       "0    non-stop         No info   3897             False              False   \n",
       "1     2 stops         No info   7662             False               True   \n",
       "2     2 stops         No info  13882             False              False   \n",
       "3      1 stop         No info   6218             False              False   \n",
       "4      1 stop         No info  13302             False              False   \n",
       "\n",
       "   ...  Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n",
       "0  ...           False         False           False          False   \n",
       "1  ...           False         False            True          False   \n",
       "2  ...           False          True           False          False   \n",
       "3  ...           False         False            True          False   \n",
       "4  ...           False         False           False          False   \n",
       "\n",
       "   Destination_Banglore  Destination_Cochin  Destination_Delhi  \\\n",
       "0                 False               False              False   \n",
       "1                  True               False              False   \n",
       "2                 False                True              False   \n",
       "3                  True               False              False   \n",
       "4                 False               False              False   \n",
       "\n",
       "   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n",
       "0                  False                False                   True  \n",
       "1                  False                False                  False  \n",
       "2                  False                False                  False  \n",
       "3                  False                False                  False  \n",
       "4                  False                False                   True  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.get_dummies(data = data, columns = ['Airline', 'Source', 'Destination'])\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4839702a-295c-4f62-b6f6-1068fc70a188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below, we will compare our original data frame with the transformed one.\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ab308df-4471-4c86-99f3-abcdea217288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 29)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0ff4fb2-0783-4a32-a164-b6191ab46b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "#Since 'Total_Stops' is originally a categorical data type, \n",
    "#we also need to convert it into numerical one. For this, we can perform\n",
    "#a label encoding, where values are manually assigned to the corresponding keys,\n",
    "#like \"0\" to a \"non-stop\", using the replace() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "912f2ad7-9d72-449f-84ad-fe9fa5e5fcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Airline_Air Asia</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>...</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Banglore</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date_of_Journey                  Route Dep_Time  Arrival_Time Duration  \\\n",
       "0      24/03/2019              BLR → DEL    22:20  01:10 22 Mar   2h 50m   \n",
       "1       1/05/2019  CCU → IXR → BBI → BLR    05:50         13:15   7h 25m   \n",
       "2       9/06/2019  DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h   \n",
       "3      12/05/2019        CCU → NAG → BLR    18:05         23:30   5h 25m   \n",
       "4      01/03/2019        BLR → NAG → DEL    16:50         21:35   4h 45m   \n",
       "\n",
       "   Total_Stops Additional_Info  Price  Airline_Air Asia  Airline_Air India  \\\n",
       "0            0         No info   3897             False              False   \n",
       "1            2         No info   7662             False               True   \n",
       "2            2         No info  13882             False              False   \n",
       "3            1         No info   6218             False              False   \n",
       "4            1         No info  13302             False              False   \n",
       "\n",
       "   ...  Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n",
       "0  ...           False         False           False          False   \n",
       "1  ...           False         False            True          False   \n",
       "2  ...           False          True           False          False   \n",
       "3  ...           False         False            True          False   \n",
       "4  ...           False         False           False          False   \n",
       "\n",
       "   Destination_Banglore  Destination_Cochin  Destination_Delhi  \\\n",
       "0                 False               False              False   \n",
       "1                  True               False              False   \n",
       "2                 False                True              False   \n",
       "3                  True               False              False   \n",
       "4                 False               False              False   \n",
       "\n",
       "   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n",
       "0                  False                False                   True  \n",
       "1                  False                False                  False  \n",
       "2                  False                False                  False  \n",
       "3                  False                False                  False  \n",
       "4                  False                False                   True  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.replace({\n",
    "    \"non-stop\": 0, \"1 stop\": 1, \"2 stops\":2, \"3 stops\": 3, \"4 stops\": 4}, inplace =True)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50274445-2e5a-4618-9271-a6eab5cbb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "#Here, we will select only those attributes which best explain the relationship of the \n",
    "#independent variables with respect to the target variable, 'price'. There are many \n",
    "#methods for feature selection, building the heatmap and calculating the correlation \n",
    "#coefficients scores are the most commonly used ones.\n",
    "\n",
    "#First, we will select only the relevant and newly transformed variables \n",
    "#(and exclude variables such as 'Route', 'Additional_Info', and all the original \n",
    "#categorical variables), and place them into a 'new_data' data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddc06267-02a8-4399-a1cd-f3a1e745c582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date_of_Journey', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration',\n",
       "       'Total_Stops', 'Additional_Info', 'Price', 'Airline_Air Asia',\n",
       "       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
       "       'Airline_Jet Airways', 'Airline_Multiple carriers',\n",
       "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
       "       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n",
       "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
       "       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n",
       "       'Destination_Hyderabad', 'Destination_Kolkata',\n",
       "       'Destination_New Delhi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#will print all of our data1 columns.\n",
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b41fa1eb-6806-47ba-8f4f-d7b99cca8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will construct a heatmap(), using the seaborn library with a newly formed data frame, 'new_data'.\n",
    "new_data = data1.loc[:,['Date_of_Journey', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration',\n",
    "       'Total_Stops', 'Additional_Info', 'Price', 'Airline_Air Asia',\n",
    "       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
    "       'Airline_Jet Airways', 'Airline_Multiple carriers',\n",
    "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
    "       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n",
    "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
    "       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n",
    "       'Destination_Hyderabad', 'Destination_Kolkata',\n",
    "       'Destination_New Delhi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "350b93e2-df07-4fd1-bacd-e1f4308fba1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m18\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mheatmap(new_data\u001b[38;5;241m.\u001b[39mcorr(), annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRdYlGn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "sns.heatmap(new_data.corr(), annot=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4732f512-85e7-4c9f-b457-2fa5bd06e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the heatmap above, extreme green means highly positively correlated features \n",
    "#(relationship between two variables in which both variables move in the same direction),\n",
    "#extreme red means negatively correlated features (relationship between two variables in \n",
    "#which an increase in one variable is associated with a decrease in the other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4988e291-d24c-4709-938e-e4a1ab8ce827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we can use the `corr()` function to calculate and list the correlation between \n",
    "#all independent variables and the 'price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42dcdf5b-e90a-4459-9f28-076ecc02c801",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '24/03/2019'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mnew_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values()\n\u001b[0;32m      2\u001b[0m features\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '24/03/2019'"
     ]
    }
   ],
   "source": [
    "features = new_data.corr()['Price'].sort_values()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c18ca6-954c-44d4-b10b-c78728fa4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also plot these correlation coefficients for easier visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1ca57-e161-4edf-affd-b46f62bfa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.plot(kind='bar',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3471640f-3634-4dec-9cb4-c3a9e772242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the graph above, we can deduct some of the highly correlated features and select\n",
    "#only those ones for any future analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81739807-3866-48fb-8e50-4493b21200b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Feature Extraction using Principal Component Analysis (Optional)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cc3acd2-ff7c-4e9e-bafe-6c436d65e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **PCA with Scikit-Learn**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3efa36b-6d44-4777-93d4-d47f371a6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimentionality reduction is part of the feature extraction process that combines the \n",
    "#existing features to produce more useful ones. The goal of dimensionality reduction is \n",
    "#to simplify the data without loosing too much information. Principal Component Analysis\n",
    "#(PCA) is one of the most popular dimensionality reduction algorithms. First, it identifies\n",
    "#the hyperplane that lies closest to the data, and then it projects the data onto it. In\n",
    "#this way, a few multidimensional features are merged into one.\n",
    "\n",
    "#In the following portion of the lab, we will use `scikit-learn` library to perform some PCA \n",
    "#on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b9845de-9e26-48b5-ba1f-2c27026fe8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we must scale our data using the `StandardScaler()` function.\n",
    "#We will assign all the independent variables to x, and the dependent variable, \n",
    "#'price', to y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13b631ec-674c-444f-bdf5-32a0e36eb295",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1.loc[:,['Date_of_Journey', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration',\n",
    "       'Total_Stops', 'Additional_Info', 'Price', 'Airline_Air Asia',\n",
    "       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
    "       'Airline_Jet Airways', 'Airline_Multiple carriers',\n",
    "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
    "       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n",
    "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
    "       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n",
    "       'Destination_Hyderabad', 'Destination_Kolkata',\n",
    "       'Destination_New Delhi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b616cc01-72a1-4034-8bd5-d0e895f5fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data1.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a350c697-10ad-409f-b859-d513fe00d2bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '24/03/2019'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 2\u001b[0m x\u001b[38;5;241m=\u001b[39mscaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '24/03/2019'"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x=scaler.fit_transform(x.astype(np.float64))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f225c8a6-de0c-4d3c-99a8-43e44916f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the data is scaled, we can apply the `fit_transform()` function\n",
    "#to reduce the dimensionality of the dataset down to two dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bab57c64-7cc6-4bdc-84e0-08caa6134699",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '24/03/2019'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:468\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:505\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    497\u001b[0m     )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:973\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    972\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 973\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    975\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '24/03/2019'"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7940fd-32ac-4a8a-a605-c95e359c0d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
